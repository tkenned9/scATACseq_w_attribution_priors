{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "import scipy.stats\n",
    "import scipy.ndimage\n",
    "import sklearn.metrics\n",
    "import pyfaidx\n",
    "import pyBigWig\n",
    "import tqdm\n",
    "import project as proj\n",
    "import importlib\n",
    "from dinuc_shuffle import dinuc_shuffle\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_path = './data/vcm_reads.bw'\n",
    "open_regions_path = './data/vcm_peaks.bed'\n",
    "chrom_sizes_path = './data/hg38.canon.chrom.sizes'\n",
    "ref_fasta_path = './data/hg38.fasta'\n",
    "reads = pyBigWig.open(reads_path)\n",
    "train_regions_npy_path = \"./data/train_regions.npy\"\n",
    "val_regions_npy_path = \"./data/val_regions.npy\"\n",
    "test_regions_npy_path = \"./data/test_regions.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVNULL = open(os.devnull, \"w\")\n",
    "STDOUT = sys.stdout\n",
    "\n",
    "\n",
    "def hide_stdout():\n",
    "    sys.stdout = DEVNULL\n",
    "def show_stdout():\n",
    "    sys.stdout = STDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from https://github.com/amtseng/fourier_attribution_priors/blob/master/src/extract/compute_shap.py\n",
    "\n",
    "\n",
    "def create_input_seq_background(\n",
    "    input_seq, input_length, bg_size=10, seed=20200219, cuda=0\n",
    "):\n",
    "    \"\"\"\n",
    "    From the input sequence to a model, generates a set of background\n",
    "    sequences to perform interpretation against.\n",
    "    Arguments:\n",
    "        `input_seq`: I x 4 tensor of one-hot encoded input sequence, or None\n",
    "        `input_length`: length of input, I\n",
    "        `bg_size`: the number of background examples to generate, G\n",
    "    Returns a G x I x 4 tensor containing randomly dinucleotide-shuffles of the\n",
    "    original input sequence. If `input_seq` is None, then a G x I x 4 tensor of\n",
    "    all 0s is returned.\n",
    "    \"\"\"\n",
    "    if input_seq is None:\n",
    "        input_seq_bg_shape = (bg_size, input_length, 4)\n",
    "        return proj.place_tensor(torch.zeros(input_seq_bg_shape), cuda).float()\n",
    "\n",
    "    # Do dinucleotide shuffles\n",
    "    input_seq_np = input_seq.cpu().numpy()\n",
    "    rng = np.random.RandomState(seed)\n",
    "    input_seq_bg_np = dinuc_shuffle(input_seq_np, bg_size, rng=rng)\n",
    "    return proj.place_tensor(torch.tensor(input_seq_bg_np), cuda).float()\n",
    "\n",
    "def combine_input_seq_mult_and_diffref(mult, orig_inp, bg_data):\n",
    "    \"\"\"\n",
    "    Computes the hypothetical contribution of any base along the input sequence\n",
    "    to the final output, given the multipliers for the input sequence\n",
    "    background. This will simulate all possible base identities as compute a\n",
    "    \"difference-from-reference\" for each possible base, averaging the product\n",
    "    of the multipliers with the differences, over the base identities.\n",
    "    Arguments:\n",
    "        `mult`: a G x I x 4 array containing multipliers for the background\n",
    "            input sequences\n",
    "        `orig_inp`: the target input sequence to compute contributions for, an\n",
    "            I x 4 array\n",
    "        `bg_data`: a G x I x 4 array containing the actual background sequences\n",
    "    Returns the hypothetical importance scores in an I x 4 array.\n",
    "    This function is necessary for this specific implementation of DeepSHAP. In\n",
    "    the original DeepSHAP, the final step is to take the difference of the input\n",
    "    sequence to each background sequence, and weight this difference by the\n",
    "    contribution multipliers for the background sequence. However, all\n",
    "    differences to the background would be only for the given input sequence\n",
    "    (i.e. the actual importance scores). To get the hypothetical importance\n",
    "    scores efficiently, we try every possible base for the input sequence, and\n",
    "    for each one, compute the difference-from-reference and weight by the\n",
    "    multipliers separately. This allows us to compute the hypothetical scores\n",
    "    in just one pass, instead of running DeepSHAP many times. To get the actual\n",
    "    scores for the original input, simply extract the entries for the bases in\n",
    "    the real input sequence.\n",
    "    \"\"\"\n",
    "    # Reassign arguments to better names; this specific implementation of\n",
    "    # DeepSHAP requires the arguments to have the above names\n",
    "    bg_mults, input_seq, bg_seqs = mult, orig_inp, bg_data\n",
    "\n",
    "    # Allocate array to store hypothetical scores, one set for each background\n",
    "    # reference (i.e. each difference-from-reference)\n",
    "    input_seq_hyp_scores_eachdiff = np.empty_like(bg_seqs)\n",
    "    \n",
    "    # Loop over the 4 input bases\n",
    "    for i in range(input_seq.shape[-1]):\n",
    "        # Create hypothetical input of all one type of base\n",
    "        hyp_input_seq = np.zeros_like(input_seq)\n",
    "        hyp_input_seq[:, i] = 1\n",
    "\n",
    "        # Compute difference from reference for each reference\n",
    "        diff_from_ref = np.expand_dims(hyp_input_seq, axis=0) - bg_seqs\n",
    "        # Shape: G x I x 4\n",
    "\n",
    "        # Weight difference-from-reference by multipliers\n",
    "        contrib = diff_from_ref * bg_mults\n",
    "\n",
    "        # Sum across bases axis; this computes the actual importance score AS IF\n",
    "        # the target sequence were all that base\n",
    "        input_seq_hyp_scores_eachdiff[:, :, i] = np.sum(contrib, axis=-1)\n",
    "\n",
    "    # Average hypothetical scores across background\n",
    "    # references/diff-from-references\n",
    "    return np.mean(input_seq_hyp_scores_eachdiff, axis=0)\n",
    "\n",
    "class WrapperProfileModel(torch.nn.Module):\n",
    "    def __init__(self, inner_model, task_index=None):\n",
    "        \"\"\"\n",
    "        Takes a profile model and constructs wrapper model around it. This model\n",
    "        takes in the same inputs (i.e. input tensor of shape B x I x 4 and\n",
    "        perhaps a set of control profiles of shape B x (T or 1) x O x S). The\n",
    "        model will return an output of B x 1, which is the profile logits\n",
    "        (weighted), aggregated to a scalar for each input.\n",
    "        Arguments:\n",
    "            `inner_model`: a trained `ProfilePredictorWithMatchedControls`,\n",
    "                `ProfilePredictorWithSharedControls`, or\n",
    "                `ProfilePredictorWithoutControls`\n",
    "            `task_index`: a specific task index (0-indexed) to perform\n",
    "                explanations from (i.e. explanations will only be from the\n",
    "                specified outputs); by default explains all tasks in aggregate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.inner_model = inner_model\n",
    "        self.task_index = task_index\n",
    "        \n",
    "    def forward(self, input_seqs, cont_profs=None):\n",
    "        # Run through inner model, disregarding the predicted counts\n",
    "        logit_pred_profs, _ = self.inner_model(input_seqs, cont_profs)\n",
    "       \n",
    "        # As with the computation of the gradients, instead of explaining the\n",
    "        # logits, explain the mean-normalized logits, weighted by the final\n",
    "        # probabilities after passing through the softmax; this exponentially\n",
    "        # increases the weight for high-probability positions, and exponentially\n",
    "        # reduces the weight for low-probability positions, resulting in a\n",
    "        # cleaner signal\n",
    "\n",
    "        # Subtract mean along output profile dimension; this wouldn't change\n",
    "        # softmax probabilities, but normalizes the magnitude of the logits\n",
    "        norm_logit_pred_profs = logit_pred_profs - \\\n",
    "            torch.mean(logit_pred_profs, dim=2, keepdim=True)\n",
    "\n",
    "        # Weight by post-softmax probabilities, but detach it from the graph to\n",
    "        # avoid explaining those\n",
    "        pred_prof_probs = proj.profile_logits_to_log_probs(\n",
    "            logit_pred_profs\n",
    "        ).detach()\n",
    "        weighted_norm_logits = norm_logit_pred_profs * pred_prof_probs\n",
    "\n",
    "        if self.task_index is not None:\n",
    "            # Subset to specific task\n",
    "            weighted_norm_logits = \\\n",
    "                weighted_norm_logits[:, self.task_index : (self.task_index + 1)]\n",
    "        prof_sum = torch.sum(weighted_norm_logits, dim=(1, 2, 3))\n",
    "\n",
    "        # DeepSHAP requires the shape to be B x 1\n",
    "        return torch.unsqueeze(prof_sum, dim=1)\n",
    "    \n",
    "def create_profile_explainer(\n",
    "    model, input_length, profile_length, num_tasks, num_strands, controls,\n",
    "    task_index=None, bg_size=10, seed=20200219, cuda=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a trained `ProfilePredictor` model, creates a Shap DeepExplainer that\n",
    "    returns hypothetical scores for given input sequences.\n",
    "    Arguments:\n",
    "        `model`: a trained `ProfilePredictorWithMatchedControls`,\n",
    "            `ProfilePredictorWithSharedControls`, or\n",
    "            `ProfilePredictorWithoutControls`\n",
    "        `input_length`: length of input sequence, I\n",
    "        `profile_length`: length of output profiles, O\n",
    "        `num_tasks`: number of tasks in model, T\n",
    "        `num_strands`: number of strands in model, T\n",
    "        `controls`: the kind of controls used: \"matched\", \"shared\", or None;\n",
    "            if \"matched\", the control profiles taken in and returned are\n",
    "            T x O x S; if \"shared\", the profiles are 1 x O x S; if None, no\n",
    "            controls need to be provided\n",
    "        `task_index`: a specific task index (0-indexed) to perform explanations\n",
    "            from (i.e. explanations will only be from the specified outputs); by\n",
    "            default explains all tasks\n",
    "        `bg_size`: the number of background examples to generate\n",
    "    Returns a function that takes in input sequences (B x I x 4 array) and\n",
    "    control profiles (B x (T or 1) x O x S array, or nothing at all), and\n",
    "    outputs hypothetical scores for the input sequences (B x I x 4 array).\n",
    "    \"\"\"\n",
    "    wrapper_model = WrapperProfileModel(model, task_index=task_index)\n",
    "\n",
    "    def bg_func(model_inputs):\n",
    "        \"\"\"\n",
    "        Given a pair of inputs to the wrapper model, returns the backgrounds\n",
    "        for the model.\n",
    "        Arguments:\n",
    "            `model_inputs`: a list of either the input sequence (I x 4 tensor)\n",
    "                alone, or a pair of the input sequence and control profiles \n",
    "                ((T or 1) x O x S tensor), depending on `controls`\n",
    "        If `controls` is None, the `model_inputs` must be just the input\n",
    "        sequence, and this returns a list of just the input sequence background\n",
    "        (G x I x 4 tensor). Otherwise, `model_inputs` must be the pair of the\n",
    "        input sequence and control profiles, and this function will return a\n",
    "        pair of tensors: the G x I x 4 tensor for the background input\n",
    "        sequences, and a G x (T or 1) x O x S tensor of background control\n",
    "        profiles.\n",
    "        Note that in the PyTorch implementation of DeepSHAP, `model_inputs` may\n",
    "        be None, in which case this function still needs to return tensors, but\n",
    "        of the right shapes.\n",
    "        \"\"\"\n",
    "        if controls is None:\n",
    "            if model_inputs is None:\n",
    "                input_seq = None\n",
    "            else:\n",
    "                input_seq = model_inputs[0]\n",
    "            return [create_input_seq_background(\n",
    "                input_seq, input_length, bg_size=bg_size, seed=seed, cuda=cuda\n",
    "            )]\n",
    "        else:\n",
    "            if model_inputs is None:\n",
    "                input_seq, control_profs = None, None\n",
    "            else:\n",
    "                input_seq, control_profs = model_inputs\n",
    "            return [\n",
    "                create_input_seq_background(\n",
    "                    input_seq, input_length, bg_size=bg_size, seed=seed, cuda=cuda\n",
    "                ),\n",
    "                create_profile_control_background(\n",
    "                    control_profs, profile_length, num_tasks, num_strands,\n",
    "                    controls=controls, bg_size=bg_size\n",
    "                )\n",
    "            ]\n",
    "\n",
    "    def combine_mult_and_diffref_func(mult, orig_inp, bg_data):\n",
    "        \"\"\"\n",
    "        Computes the hypothetical contribution of any base along the inputs\n",
    "        to the final output. This is a wrapper function around\n",
    "        `combine_input_seq_mult_and_diffref` (further information can be found\n",
    "        there). Note that the arguments must be named as such in this\n",
    "        implementation of DeepSHAP.\n",
    "        Arguments:\n",
    "            `mult`: the multipliers for the background data; if `controls` is\n",
    "                None, then this a list of just the G x I x 4 array of input\n",
    "                sequence backgrounds; otherwise, this is a pair of input\n",
    "                sequence and control profile backgrounds (a G x (T or 1) x O x S\n",
    "                array)\n",
    "            `orig_inp`: the original target inputs; if `controls` is None, then\n",
    "                this is a list of just the I x 4 array of input sequence;\n",
    "                otherwise, it is a pair of the input sequence and a\n",
    "                (T or 1) x O x S array of control profiles\n",
    "            `bg_data`: the backgrounds themselves; if `controls` is None, then\n",
    "                this is a list of just the G x I x 4 array of input sequence\n",
    "                backgrounds; otherwise, it is a pair of the input sequence and\n",
    "                control profile backgrounds (the latter is a\n",
    "                G x (T or 1) x O x S) array\n",
    "        If `controls` is None, returns a list of just the hypothetical\n",
    "        importance scores of the input sequence; if `controls` is not None (to\n",
    "        be consistent with other profile model explaining functions), this will\n",
    "        return a pair of the input sequence scores, and an array of all zeros,\n",
    "        of shape (T or 1) x O x S.\n",
    "        \"\"\"\n",
    "        if controls is None:\n",
    "            input_seq_bg_mult = mult[0]\n",
    "            input_seq = orig_inp[0]\n",
    "            input_seq_bg = bg_data[0]\n",
    "        else:\n",
    "            input_seq_bg_mult, cont_profs_bg_mult = mult\n",
    "            input_seq, cont_profs = orig_inp\n",
    "            input_seq_bg, cont_profs_bg = bg_data\n",
    "        \n",
    "        input_seq_scores = combine_input_seq_mult_and_diffref(\n",
    "            input_seq_bg_mult, input_seq, input_seq_bg\n",
    "        )\n",
    "        if controls is None:\n",
    "            return [input_seq_scores]\n",
    "        else:\n",
    "            return [input_seq_scores, np.zeros_like(cont_profs)]\n",
    "\n",
    "    explainer = shap.DeepExplainer(\n",
    "        model=wrapper_model,\n",
    "        data=bg_func,\n",
    "        combine_mult_and_diffref=combine_mult_and_diffref_func\n",
    "    )\n",
    "\n",
    "    def explain_fn(\n",
    "        input_seqs, cont_profs=None, batch_size=128, hide_shap_output=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Given input sequences and control profiles, returns hypothetical scores\n",
    "        for the input sequences.\n",
    "        Arguments:\n",
    "            `input_seqs`: a B x I x 4 array\n",
    "            `cont_profs`: a B x (T or 1) x O x S array, or None\n",
    "            `batch_size`: batch size for computation\n",
    "            `hide_shap_output`: if True, do not show any warnings from DeepSHAP\n",
    "        Returns a B x I x 4 array containing hypothetical importance scores for\n",
    "        each of the B input sequences.\n",
    "        \"\"\"\n",
    "        scores = np.empty_like(input_seqs)\n",
    "        input_seqs_t = proj.place_tensor(torch.tensor(input_seqs), cuda).float()\n",
    "        try:\n",
    "            if hide_shap_output:\n",
    "                hide_stdout()\n",
    "            if controls is None:\n",
    "                return explainer.shap_values(\n",
    "                    [input_seqs_t], progress_message=None\n",
    "                )[0]\n",
    "            else:\n",
    "                cont_profs_t = proj.place_tensor(torch.tensor(cont_profs), cuda).float()\n",
    "                return explainer.shap_values(\n",
    "                    [input_seqs_t, cont_profs_t], progress_message=None\n",
    "                )[0]\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        finally:\n",
    "            show_stdout()\n",
    "\n",
    "    return explain_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_scores(model_name, data_path, cuda = 0):\n",
    "    print(\"Testing profile model\")\n",
    "    input_length = 1346\n",
    "    profile_length = 1000\n",
    "    controls = None\n",
    "    num_tasks = 1\n",
    "    num_strands = 1\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    device = torch.device(\"cuda:\" + str(cuda)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model = proj.restore_model(model_name, cuda)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(\"Creating explainer...\")\n",
    "    explainer = create_profile_explainer(\n",
    "        model, input_length, profile_length, num_tasks, num_strands, controls=None, cuda=0\n",
    "    )\n",
    "\n",
    "    loader = proj.DataLoader(data_path,batch_size=8385)\n",
    "    input_seqs, profiles = loader[0]\n",
    "\n",
    "    \n",
    "\n",
    "    hyp_scores = explainer(\n",
    "        input_seqs, profiles, hide_shap_output=True\n",
    "    )\n",
    "\n",
    "    return hyp_scores, profiles, input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_no_prior, val_no_prior_profs, val_no_prior_input_seqs  = compute_shap_scores('./trained_models/exp5_epoch_17.pt',val_regions_npy_path, cuda=0 )\n",
    "val_prior, val_prior_profs, val_prior_input_seqs = compute_shap_scores('./trained_models/exp6_prior_epoch_20.pt',val_regions_npy_path, cuda=0 )\n",
    "np.save('./shap/val_shap.npy', val_no_prior)\n",
    "np.save('./shap/val_prior_shap.npy', val_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_prior, test_profs, test_input_seqs = compute_shap_scores('./trained_models/exp5_epoch_17.pt',test_regions_npy_path, cuda=0 )\n",
    "test_prior, test_prior_profs, test_prior_input_seqs = compute_shap_scores('./trained_models/exp6_prior_epoch_20.pt',test_regions_npy_path, cuda=0 )\n",
    "np.save('./shap/test_prof.npy', test_profs)\n",
    "np.save('./shap/test_prior_prof.npy', test_prior_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(model_name, data_path, cuda = 0):\n",
    "    loader = proj.DataLoader(data_path,batch_size=8385)\n",
    "    input_seqs, profiles = loader[0]\n",
    "    return input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_seqs = get_inputs('./trained_models/exp5_epoch_17.pt',test_regions_npy_path, cuda=0 )\n",
    "np.save('./shap/test_input_seqs.npy', test_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
