{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.font_manager as font_manager\n",
    "import viz_sequence as viz_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import json\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shap = np.load('./shap/test_shap.npy')\n",
    "test_prior_shap = np.load('./shap/test_prior_shap.npy')\n",
    "val_shap = np.load('./shap/val_shap.npy')\n",
    "val_prior_shap = np.load('./shap/val_prior_shap.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from https://github.com/amtseng/fourier_attribution_priors/blob/27b95141da26f1c7d388db9046e9d06b1a7b5df9/notebooks/view_profile_predictions.ipynb\n",
    "\n",
    "def dft(signal):\n",
    "    fourier_coeffs = np.fft.fft(signal)\n",
    "    fourier_freqs = 2 * np.pi * np.fft.fftfreq(signal.size)\n",
    "    fourier_freqs = fourier_freqs[:int(len(fourier_freqs) / 2)]  # Only the positive frequencies\n",
    "    mags = np.abs(fourier_coeffs)[:int(len(fourier_coeffs) / 2)]  # Frequency magnitudes are symmetric\n",
    "    return fourier_freqs, mags\n",
    "\n",
    "\n",
    "def fourier_highfreq_mags(imp_scores, freq_limit):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the sum of the\n",
    "    Fourier magnitudes in high frequencies, defined by `freq_limit`. Returns an\n",
    "    N-array of Fourier scores (i.e. sum of low-frequency magnitudes)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    \n",
    "    for score_track in imp_scores_sum:\n",
    "        freqs, mags = dft(score_track)\n",
    "        freqs, mags = freqs[1:], mags[1:]  # Cut off DC\n",
    "        mags = mags / np.sum(mags)  # Normalize\n",
    "        scores.append(np.sum(mags[freq_limit:]))\n",
    "    return np.array(scores)\n",
    "\n",
    "def entropy(imp_scores, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the entropy\n",
    "    of each track. Returns an N-array of entropy values.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    imp_scores_sum = imp_scores_sum + pseudocount\n",
    "    imp_scores_norm = imp_scores_sum / np.sum(imp_scores_sum, axis=1, keepdims=True)\n",
    "    \n",
    "    return -np.sum(imp_scores_norm * np.log2(imp_scores_norm), axis=1)\n",
    "\n",
    "\n",
    "def plot_global_smoothness(\n",
    "    noprior_imp_fourier_scores, prior_imp_fourier_scores, noprior_imp_entropy_scores,\n",
    "    prior_imp_entropy_scores, imp_type\n",
    "):\n",
    "    bin_num = 20\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    all_vals = np.concatenate([noprior_imp_fourier_scores, prior_imp_fourier_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[0].hist(noprior_imp_fourier_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[0].hist(prior_imp_fourier_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[0].set_xlabel(\"Sum of high-frequency Fourier magnitudes\")\n",
    "    all_vals = np.concatenate([noprior_imp_entropy_scores, prior_imp_entropy_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[1].hist(noprior_imp_entropy_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[1].hist(prior_imp_entropy_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[1].set_xlabel(\"Entropy\")\n",
    "    ax[1].legend()\n",
    "    title = \"Histograms of smoothness of %s\"\n",
    "    title += \"\\n%s profile models\"\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\"\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    def draw_xy_line(ax):\n",
    "        limits = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "        ]\n",
    "        ax.plot(limits, limits, \"--\", alpha=0.5, color=\"black\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlim(limits)\n",
    "        ax.set_ylim(limits)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    ax[0].scatter(noprior_imp_fourier_scores, prior_imp_fourier_scores, color=\"mediumorchid\", alpha=0.4)\n",
    "    ax[0].set_xlabel(\"High frequency sum without prior\")\n",
    "    ax[0].set_ylabel(\"High frequency sum with Fourier prior\")\n",
    "    ax[1].scatter(noprior_imp_entropy_scores, prior_imp_entropy_scores, color=\"mediumorchid\", alpha=0.4)\n",
    "    ax[1].set_xlabel(\"Entropy without prior\")\n",
    "    ax[1].set_ylabel(\"Entropy with Fourier prior\")\n",
    "    draw_xy_line(ax[0])\n",
    "    draw_xy_line(ax[1])\n",
    "    title = \"Pairwise comparison of %s smoothness\"\n",
    "    title += \"\\n%s profile models\"\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\"\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"High-frequency Fourier sum:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_fourier_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_fourier_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_fourier_scores, prior_imp_fourier_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))\n",
    "    print(\"Entropy:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_entropy_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_entropy_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_entropy_scores, prior_imp_entropy_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistical Tests and Visualizations\n",
    "\n",
    "condition_name = \"BPNet\"\n",
    "test_input_seqs = np.load('./shap/test_input_seqs.npy')\n",
    "test_entropy = entropy(test_shap*test_input_seqs)\n",
    "test_prior_entropy = entropy(test_prior_shap*test_input_seqs)\n",
    "test_mags = fourier_highfreq_mags(test_shap*test_input_seqs, 200)\n",
    "test_prior_mags = fourier_highfreq_mags(test_prior_shap*test_input_seqs, 200)\n",
    "plot_global_smoothness(\n",
    "    test_mags, test_prior_mags, test_entropy,\n",
    "    test_prior_entropy, \"DeepSHAP scores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specific Example\n",
    "\n",
    "test_scores = test_shap*test_input_seqs\n",
    "test_scores_prior = test_prior_shap*test_input_seqs\n",
    "test_prof = np.load('./shap/test_prof.npy')\n",
    "x = np.arange(0,1346)\n",
    "prof_padded = np.pad(test_prof[1], (173, 173))\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.xticks(np.arange(0,1346,100))\n",
    "plt.xlim((0,1346))\n",
    "x = plt.plot(x,prof_padded, color='blue',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights(test_scores[1], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights(test_scores_prior[1], subticks_frequency=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights(test_scores[1][650:750], subticks_frequency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights(test_scores_prior[1][650:750], subticks_frequency=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
